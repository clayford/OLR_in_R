---
title: "Ordinal Logistic Regression in R"
author: "Clay Ford, UVA Library"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---


This is an R Markdown Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter* (Win/Linux) or *Cmd+Shift+Return* (Mac). 

```{r}
# trees is a data set that comes with R
pairs(trees)
```

To hide the output, click the Expand/Collapse output button. To clear results (or an error), click the "x". 

You can also press *Ctrl+Enter* (Win/Linux) or *Cmd+Return* (Mac) to run one line of code at a time (instead of the entire chunk).

Add a new R code chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I* (Win/Linux) or *Cmd+Option+I* (Mac).  

## CODE ALONG 0

Try the `cumsum()` function with the vector `1:5`



## Load Packages

We'll use the following packages in today's workshop.

```{r}
library(vcd)
library(MASS)
library(car)
library(effects)
library(ggplot2)
library(ggeffects)
library(emmeans)
```

## Review: Probabilities and Cumulative Probabilities

Let's say I randomly sample 100 UVA students and ask them to rate how spicy they like their food on a scale of 1 - 5, where 1 is no spice and 5 is maximum spiciness. Below are made up responses entered manually using a named vector.

```{r}
resp <- c("1 none" = 17,
          "2 mild" = 23,
          "3 medium" = 31,
          "4 hot" = 21,
          "5 maximum" = 8)
resp
```

I can calculate proportions from this data and use these as estimates of _probabilities_. Using the `proportions()` function on a vector of numbers returns the proportion of each value relative to the total of the vector.

```{r}
proportions(resp)
```

Based on this random sample I might estimate that a randomly selected UVA student has a probability of about 0.31 of liking medium spicy food. I'm using my observed proportion as an estimate of probability.

Another way to summarize the results is with _cumulative probabilities_. For example, what's the the probability a randomly selected student can handle _medium heat or less_? Using the `cumsum()` we can calculate cumulative sums of proportions and answer this question. Below we take the proportions and "pipe" into the `cumsum()` function using the base R pipe operator. 

```{r}
proportions(resp) |> cumsum()
```

Based on this calculation I might estimate that a randomly selected student has a probability of about 0.71 of liking _medium or lower_ spiciness. We might state this mathematically as follows (using LaTeX):

$$P[X \le \text{medium}] = 0.71 $$

In this case we're using the _ordering of the responses_ to make additional inferences about student spiciness preference. 

What if we also collected additional information such as the sex of the respondents? Does being male or female affect the _cumulative probability_ of 0.71? 

What about age or weight? Does being older and heavier affect the _cumulative probability_ of spiciness preference?

_Ordinal Logistic Regression_ is a method that allows us to investigate questions such as this. It allows us to _model the cumulative probability_ of an ordered category given multiple predictors.

Performing Ordinal Logistic Regression is like fitting any other statistical model. We have to...

1. propose and fit a model
2. assess if the model is good
3. use the model to make predictions and/or quantify relationships

## Load Data for the workshop

Today we'll work with data from a double-blind clinical trial investigating a new treatment for rheumatoid arthritis (Koch & Edwards, 1988). The data is available in the vcd package (Meyer et al, 2022)

```{r}
data("Arthritis", package = "vcd")
```

If for some reason you can't install the vcd package, you can also download the data from GitHub:

```{r}
URL <- "https://github.com/clayford/OLR_in_R/raw/main/data/arthritis.rds"
Arthritis <- readRDS(file = url(URL))
```

### List of variables

```{r}
names(Arthritis)
```

- ID: patient ID
- Treatment: factor indicating treatment (Placebo, Treated).
- Sex: factor indicating sex (Female, Male).
- Age: age of patient in years
- Improved: _ordered factor_ indicating treatment outcome (None, Some, Marked).

The goal today is to teach the basics of Ordinal Logistic Regression by developing a model to predict the _cumulative probability_ of pain improvement after treatment adjusting for age and sex. 


## Ordered Factors in R

An ordered factor is a _categorical variable with ordered levels_. Examples of ordered categorical variables include:

- Satisfaction/Recommendation ratings (Poor, Fair, Good, Excellent)
- Pain scales (none, mild, moderate, severe)
- Experience (none, some, proficient, expert)
- Likert scale ratings (strong disagree, disagree, neutral, agree, strong agree) 

We can format a categorical variable as an ordered factor using the `factor()` function with the argument `ordered = TRUE`. _We are responsible for creating the order!_ Otherwise R will set the order alphabetically. 

Quick example using fake data. Sample from a vector of ordered levels 50 times with replacement using the `sample()` function. The result is a character vector.

```{r}
experience <- sample(c("none", "some", "proficient", "expert"), 
                     size = 50, replace = TRUE)
head(experience)
```

Let's convert to factor using the `factor()` function. Notice there is no ordering of the levels. They are simply listed alphabetically.

```{r}
experience <- factor(experience)
head(experience)
```

Now convert to _ordered factor_ using the argument `ordered = TRUE`. Notice the levels are ordered but still in alphabetical order. The notation `expert < none < proficient < some` says "expert" is less than "none", which is less than "proficient", which is less than "some". According to this ordering "some" is the highest, which doesn't make sense.

```{r}
experience <- factor(experience, ordered = TRUE)
head(experience)
```

Now let's do it the right way: specify order of levels using the `levels` argument. 

```{r}
experience <- factor(experience, ordered = TRUE, 
                     levels = c("none", "some", "proficient", "expert"))
head(experience)
```

This is an important data wrangling step when preparing for Ordinal Logistic Regression.

## Explore the Arthritis data

Our response is the Improved variable. Notice it's already an ordered categorical variable:

```{r}
head(Arthritis$Improved)
```

Let's tabulate the counts using `xtabs()`. The notation `~ Improved` means "tabulate by Improved".

```{r}
xtabs(~ Improved, data = Arthritis)
```

We an get cumulative proportions using `proportions()` and `cumsum()`. 

```{r}
xtabs(~ Improved, data = Arthritis) |>
  proportions() |>
  cumsum()
```

About 67% of subjects experienced None or Some improvement. Therefore about 33% of subjects experienced marked improvement. 

How does cumulative probability of Improved breakdown between the Treatments? The notation `~ Treatment + Improved` means "tabulate by Treatment and Improved, with Treatment in the rows and Improved in the columns." The `margin = 1` argument in `proportions()` says calculate row-wise proportions. Then we "apply" the `cumsum()` function to the rows of the table. Finally we use `t()` to rotate or "transpose" the table.

```{r}
xtabs(~ Treatment + Improved, data = Arthritis) |>
  proportions(margin = 1) |>
  apply(MARGIN = 1, cumsum) |> 
  t()
```

About 84% of subjects experienced None or Some improvement in the Placebo group versus 49% in the Treatment group. That implies only 16% experienced Marked improvement in the Placebo group versus 51% in the Treatment group.

## CODE ALONG 1

- Investigate the Age variable
- Investigate the Sex variable

Add a new R code chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I* (Win/Linux) or *Cmd+Option+I* (Mac).  


## Ordinal Logistic Regression basics

Ordinal logistic regression produces a _model_ that we can use to make cumulative probability predictions or quantify how predictors are associated with cumulative probabilities. Like binary logistic regression, the results are on the log odds scale.

Let's fit a simple model for the Arthritis data. Below we model Improved as a function of Treatment. In other words, _how does Treatment affect the cumulative probability of Improved_?

One way to do this is with the `polr()` function from the MASS package. "polr" stands for "proportional odds logistic regression". We'll explain proportional odds in a moment. As with `lm()` and `glm()`, we define our model using R's formula syntax. We also typically want to save the model result and inspect the results using `summary()`

```{r}
m1 <- polr(Improved ~ Treatment, data = Arthritis)
summary(m1)
```

The message "Re-fitting to get Hessian" means the model was refit when we called `summary()` to get a matrix called the "Hessian" in order to compute standard errors. To suppress this message, use `Hess = TRUE` in the call to `polr()`.

Notice we have _multiple intercepts_ which are listed separately from the coefficients. The separate intercepts are for _the levels below which we calculate cumulative probabilities_. Recall the levels of Improved:

None < Some < Marked

There are two cumulative probabilities we can calculate:

1. None
2. Some and lower

(Marked and lower will always be 1.)

So we have two models depending on the cumulative probability we want to model:

1. log odds(None) = 0.7499 - 1.568*Treatment 
2. log odds(Some or lower) = 1.5499 - 1.568*Treatment

Where Treatment = 1 if treated, 0 if on Placebo.

Notice _the coefficient is subtracted from the intercept_! That's the model that `polr()` fits. Also notice the _model is on the log odds, or logit, scale_. Recall that log odds is probability rescaled from [0,1] to (-Inf, + Inf). So the model predicts log odds values, which we then transform back to probability using the inverse logit.

Now let's use our model and compute cumulative probabilities "by hand". Before we do that, it's good to know how to extract the intercepts and coefficients from the model object. The model object is a list. We use the `$` operator to extract elements from it. The intercepts are in the `zeta` element and the coefficients are in the `coefficients` element. (Can also use `coef()` to extract coefficients.)

```{r}
m1$zeta
```

```{r}
m1$coefficients
```

The log odds of None given a subject was on Placebo (Treatment = 0):

log odds(None) = 0.7499 - 1.568*0 = 0.7499

That's simply the `None|Some` intercept: 0.7499107. To convert to probability, we can use the `plogis()` function. Below we pipe the `None|Some` intercept into `plogis()` and save as `p1`.

```{r}
(p1 <- m1$zeta["None|Some"] |> plogis())
```

The log odds of None given a subject was on Treatment (Treatment = 1):

log odds(None) = 0.7499 - 1.568*1

```{r}
(p2 <- (m1$zeta["None|Some"] - m1$coefficients) |> plogis())
```

So we predict about 68% of subjects on Placebo will see no improvement versus only about 31% of subjects on Treatment. 

The log odds of Some or lower given a subject was on Placebo (Treatment = 0):

log odds(Some or lower) = 1.5499 - 1.568*Treatment

That's simply the `Some|Marked` intercept: 1.5498756. 

```{r}
(p3 <- m1$zeta["Some|Marked"] |> plogis())
```

The log odds of Some or lower given a subject was on Treatment (Treatment = 1):

log odds(Some or lower) = 1.5498756 - 1.567644.

```{r}
(p4 <- (m1$zeta["Some|Marked"] - m1$coefficients) |> plogis())
```

This implies about 1 - 0.50 = 50% of Treated subjects can expect Marked improvement versus only 1 - 0.82 = 18% of subjects on Placebo.

Let's compare the predicted cumulative probabilities to the observed cumulative proportions. 

```{r}
# Observed cumulative proportions
xtabs(~ Treatment + Improved, data = Arthritis) |>
  proportions(margin = 1) |>
  apply(MARGIN = 1, cumsum) |> 
  t()
```

Now compare to our model-based predicted cumulative probabilities. I'm laying out the previously calculated probabilities as a matrix to match the layout of `xtabs()`. 

```{r}
# Modeled cumulative probabilities
matrix(c(p1, p2, p3, p4, 1, 1), nrow = 2, 
       dimnames = list("Treatment" = c("Placebo", "Treated"),
                       "Improved" = c("None", "Marked", "Some")))
```

Our model-based predictions are quite close to the observed proportions, but not identical. This is because of the _proportional odds assumption_.


## Proportional Odds

Recall: odds = p/(1 - p)

Predicted probability of Improved = None on Treatment is 0.3062450, which is stored in `p2`. The odds are calculated as 0.3062450/(1 - 0.3062450)

```{r}
p2/(1 - p2)
```

Predicted probability of Improved = None on Placebo is 0.6791592, which is stored in `p1`. The odds are calculated as 0.6791592/(1 - 0.6791592)

```{r}
p1/(1 - p1)
```

The odds ratio for those two odds are

```{r}
(p2/(1 - p2))/
(p1/(1 - p1))
```

If we take the log of that we get the model coefficient for Treatment with a change in sign. (We explain why that is shortly.)

```{r}
# compare to coef(m1)
log((p2/(1 - p2))/
(p1/(1 - p1)))
```

Now let's do the same calculation for the Some or lower cumulative probabilities:

```{r}
# p4 = P(Some or lower) if Treated
# p3 = P(Some or lower) if Placebo
log((p4/(1 - p4))/
(p3/(1 - p3)))
```

Notice we get the _same answer_. That's because according to our model, the Treatment effect is proportional to the ordered category levels. That's the proportional odds assumption. _The coefficients are independent of the levels of the ordered response_. It doesn't matter whether we go from "None" to "Some", or "Some" to "Marked", the effect of Treatment is the same.

Let's look at the coefficient from the model again.

```{r}
coef(m1)
```

This is identical to what we derived above, but with a change in sign. `polr()` multiplies the coefficients in the summary output by -1 so when you exponentiate and take the odds ratio, _higher levels of predictors correspond to the response falling in the higher end of the ordinal scale_.  

```{r}
exp(coef(m1))
```

Interpretation: the estimated odds that a Treated subject's response has higher improvement is about 4.8 times the odds that a Placebo subject's response has higher improvement

Notice if we "remove" the minus sign we get the odds ratio we calculated above.

```{r}
exp(-coef(m1))  # -coef(m1) is equivalent to -1*coef(m1)
```

Compare to:

```{r}
(p2/(1 - p2))/
(p1/(1 - p1))
```

And to:

```{r}
(p4/(1 - p4))/
(p3/(1 - p3))
```

The substance of the result remains the same, but the interpretation is reversed: The estimated odds that a Treated subject's response has lower improvement is about 80% less than the odds that a Placebo subject's response has lower improvement

## Assessing the proportional odds assumption

Earlier we mentioned that proportional odds logistic regression assumes _the coefficients are independent of the category levels_. This means we assume the estimated odds ratio of Treatment, 4.795, is the same whether we're talking about comparing None versus Some or higher, or None or Some versus Marked on the Improvement scale.

One way to assess if this assumption is satisfied is the `poTest()` function in the car package. Simply call it on the fitted model. _The null is the proportional odds assumption is true_. Rejecting the null is evidence against the assumption. The `poTest()` function provides an overall test of the PO assumption as well as separate tests for each predictor. We only have one predictor so both tests are the same. The result below implies we're safe in our assumption of proportional odds.

```{r}
poTest(m1)
```

The authors of the car package state, "It's our experience that the proportional-odds assumption is rarely supported by a hypothesis test. The proportional-odds model can nevertheless provide useful simplification of the data as long as fitted probabilities under the model aren't substantially distorted." (Fox and Weisberg, 2019, p. 322)

Our simulation above showed the fitted probabilities were not "substantially distorted".

A graphical method for assessing the proportional odds assumption is available in the rms package. The function `plot.xmean.ordinaly` plots both...

- means of predictor by ordered category level (solid line)
- expected value of predictor given category level assuming PO assumption is true (dashed line)

When the solid and dashed lines roughly follow the same trajectory, we have good evidence that the PO assumption is safe. This looks great!

```{r}
# rms:: allows us to use the function without loading the rms package
rms::plot.xmean.ordinaly(Improved ~ Treatment, data = Arthritis)
```

According to Frank Harrell, Violation of Proportional Odds is Not Fatal. See https://www.fharrell.com/post/po/

If you think proportional odds assumption is badly violated, two options to consider: 

- The _partial proportional odds model_, which allows some predictors to have multiple coefficients that vary with the response level. This can be fit using the `vglm()` function in the VGAM package. 
- The _multinomial logit model_ that assumes no ordering of categories and fits a different coefficient for each response level. This can be fit using the `multinom()` function in the nnet package. 


## Summary output and confidence intervals

Let's look again at the output summary of our model. First we'll refit the model with Hess = TRUE to suppress the "re-fitting" message.

```{r}
m1 <- polr(formula = Improved ~ Treatment, data = Arthritis, 
           Hess = TRUE)
summary(m1)
```

- The Standard Errors quantify the uncertainty in the estimated intercepts and coefficients. 
- The t values are the ratios of values to standard errors. t values larger than 2 or 3 are good evidence that the sign on the coefficient is correct. In the output above, the t value of 3.53 for the coefficient is strong evidence that the effect of treatment is positive. 
- Residual Deviance and AIC are model fit statistics used when comparing models. Lower values are better. 

The authors of the `polr()` function elected to not output p-values. P-values do not measure the magnitude of an effect. They simply provide evidence if the sign of a coefficient is reliably positive or negative. A confidence interval on the coefficient is more informative, which we demonstrate next. However if you absolutely need a p-value, you can calculate using the `pt()` function. 

1. Set `q` to t value
2. Set `df` to number of observations minus number of coefficients estimated
3. Set `lower.tail = F` to get the upper tail (ie, > t)
4. multiply by 2 to get a two-sided test

```{r}
pt(q = 3.53, df = 84 - 3, lower.tail = FALSE) * 2
```

The `coeftest()` function in the lmtest package will also return p-values.

To understand the _uncertainty of the magnitude of the coefficient_, we can calculate 95% confidence intervals using `confint()`. Notice use `exp()` to get the odds ratio. Also notice that only a CI for the predictor is calculated, not the intercepts.

```{r}
exp(confint(m1))
```

The estimated odds that a Treated subject's response has higher improvement is at least 2 times the odds that a Placebo subject's response has higher improvement, perhaps as high as 11 times.

## Using predict() with fitted models

Earlier we made predictions "by hand" (for teaching purposes) with intercept and coefficient values. In practice we would likely use `predict()` to get fitted probabilities. Using the `newdata` argument we can specify what we want to make predictions for. The default is to predict the class, or level, for the given predictors. (`type = "class"`)

The Placebo group is predicted to experience No improvement while the Treated groups is expected to experience Marked improvement.

```{r}
predict(m1, newdata = data.frame(Treatment = c("Placebo", "Treated")), 
        type = "class")
```

Changing `type = "probs` returns expected probabilities for _each class_.

```{r}
predict(m1, newdata = data.frame(Treatment = c("Placebo", "Treated")), 
        type = "probs")
```

Notice these are NOT cumulative probabilities. These are expected probabilities for each level. They sum to 1. We see that `type = "class"` setting is simply picking the category with the highest probability.

The `predict()` method unfortunately does not provide standard errors and confidence intervals for the predictions. However we can use the emmeans package to calculate. Below we obtain estimated probabilities of each level of Improved conditional on Treatment. The `mode = "prob"` argument ensures predictions are of the probabilities of each class of the ordinal response.

```{r}
emmeans(m1, ~ Improved|Treatment, mode = "prob")
```

We can pipe this result into `plot()` for a basic visualization.

```{r}
emmeans(m1, ~ Improved|Treatment, mode = "prob") |>
  plot()
```

Which leads us to the next topic.

## Visualizing the model

Between multiple intercepts, log odds, and cumulative probabilities, ordinal logistic regression output can be hard to interpret and communicate. Fortunately we have some methods for visualizing models. 

The effects package provides some good out-of-the-box lattice plots for visualizing ordinal logistic regression models. Use the `Effect` plot to specify which coefficient(s) you want to plot. In our model we only have one choice: Treatment. Then pipe into the `plot()` function. This results in a plot for each outcome. We can see the probability of Marked improvement is much higher for the Treated group than the Placebo group. Likewise the probability of no improvement is much lower in the Treated group than in the Placebo group.

```{r}
Effect(m1, focal.predictors = "Treatment") |> plot()
```

We can combine the lines into one plot as follows:

```{r}
Effect(m1, focal.predictors = "Treatment") |> 
  plot(lines=list(multiline=TRUE),
       confint=list(style="bars"))

```

Another visualization option is the "stacked" plot, though there is no indication of uncertainty. This plot is probably better suited for a numeric predictor.

```{r}
Effect(m1, focal.predictors = "Treatment") |> 
  plot(axes=list(y=list(style="stacked")))
```

If you want something created in ggplot2, the ggeffects package provides the `ggeffect()` function and associated plotting method. I think the `connect.lines = TRUE` argument is good to use.

```{r}
ggeffect(m1, terms = "Treatment") |> plot(connect.lines = TRUE)
```

## Model assessment via simulation

A good model should generate data that looks similar to our observed data. We can use the `simulate()` function to rapidly simulate many new sets of our response variable. Below we use our model to generate 200 new sets of the Improved variable. The result is a data frame with 200 columns, where each column is a simulated outcome from our model. The number of rows equals the sample size of our original data frame: 84. We're taking our 84 observed predictors and using our model to simulate the outcome, Improved.

```{r}
sims <- simulate(m1, nsim = 200)
dim(sims)
```

Here's a glimpse of the first 5 simulations:

```{r}
sims[1:5,1:5]
```

Let's calculate the proportion of each response within each simulation using `xtabs()` and `proportions()`. The last function, `as.data.frame()` converts the table to a data frame and names the column containing the proportions "P" (the default is "Freq").

```{r}
xtabs(~ sims$sim_1) |>
  proportions() |>
  as.data.frame(responseName = "P")
```

To calculate proportions for _all columns_, we can convert the last chunk of code into a function and apply it to each column. Let's name it `p_df`. Notice it's the same code above with `x` in place of `sims$sim_1`.

```{r}
p_df <- function(x){
  xtabs(~ x) |> 
  proportions() |>
  as.data.frame(responseName = "P")
  }
```

Let's test it.

```{r}
p_df(sims$sim_1)
```

Now let's apply the function to every column of the sims data frame using `lapply` and save as `sims_p`. . The "L" in `lapply` means the result will be a list. 

```{r}
sims_p <- lapply(sims, p_df)
```

The result is a list with 200 data frames. Let's look at the first two using the `$` operator to extract the data frame

```{r}
sims_p$sim_1
```

```{r}
sims_p$sim_2
```

We can _combine all the data frames_ into one data frame using `rbind()`. The arguments to `rbind` are the data frames we want to combine. Instead of typing out all 200 data frames, we can use the `do.call()` function to "feed" all the data frames to the `rbind` function as follows. Notice I assign to an object called `sims_pdf`. 

```{r}
sims_pdf <- do.call(rbind, sims_p)
```

Now we have a data frame that we can use to create a plot using ggplot2.

```{r}
ggplot() +
  geom_jitter(mapping = aes(x = x, y = P), 
             data = sims_pdf, alpha = 0.25,
             width = 0.1, height = 0)
```

_How does this compare to the original data_? Let's add that to the plot. We need to create a data frame of the observed proportions. We can do that using the same code from above and name the result `obs_pdf`:


```{r}
obs_pdf <- xtabs(~ Improved, data = Arthritis) |> 
  proportions() |>
  as.data.frame(responseName = "P")
obs_pdf
```

Now update the plot to include the original data as big blue dots.

```{r}
ggplot() +
  # simulated data - gray dots
  geom_jitter(mapping = aes(x = x, y = P), 
             data = sims_pdf, alpha = 0.25,
             width = 0.1, height = 0) +
  # observed data - blue dots
  geom_point(mapping = aes(x = Improved, y = P), 
             data = obs_pdf, size = 4, color = "blue") 

```

The model doesn't seem biased in any way. It doesn't consistently over or under predict. We want the model-simulated data to hover around the observed data. However there is a good deal of variability. For example the model simulates "None" from 0.4 to 0.6. Then again this model is only using one binary predictor: Treatment. 


## CODE ALONG 2

Now that we've laid out the basics of fitting, assessing and using an Ordinal Logistic Regression model, let's work through a more sophisticated example with additional predictors.

- Fit an ordinal regression model with Treatment, Sex, and Age. Call it `m2`. Include `Hess = TRUE` in `polr()`
- Assess proportional odds assumption
- Interpret the coefficients
- Visualize the model
- Is the model "better" than `m1`? Use `anova(m1, m2)` to test.
- Assess model via simulation

Add a new R code chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I* (Win/Linux) or *Cmd+Option+I* (Mac).  




## We're done!

Thanks for coming! For free statistical consulting and training, contact us: `statlab@virginia.edu`


## References
- Chris Builder and Thomas Loughin (2015). Analysis of Categorical Data with R. CRC Press. URL: http://www.chrisbilder.com/categorical/
- John Fox and Sanford Weisberg (2019). An R Companion to Applied Regression, Third Edition. Thousand Oaks CA: Sage. URL: https://socialsciences.mcmaster.ca/jfox/Books/Companion/
- Michael Friendly and David Meyer (2016). Discrete Data Analysis with R. CRC Press. URL: http://ddar.datavis.ca/
- Frank Harrell (2015). Regression Modeling Strategies, 2nd edition. Springer.
- Lüdecke D (2018). “ggeffects: Tidy Data Frames of Marginal Effects from Regression Models.” _Journal of Open Source Software_, *3*(26), 772. doi:10.21105/joss.00772 <https://doi.org/10.21105/joss.00772>.
- David Meyer, Achim Zeileis, and Kurt Hornik (2022). vcd: Visualizing Categorical Data. R package version 1.4-10.
- G. Koch & S. Edwards (1988), Clinical efficiency trials with categorical data. In K. E. Peace (ed.), Biopharmaceutical Statistics for Drug Development, 403–451. Marcel Dekker, New York.
- Venables, W. N. & Ripley, B. D. (2002) Modern Applied Statistics with S. Fourth Edition. Springer, New York. ISBN 0-387-95457-0
- H. Wickham. ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York, 2016.